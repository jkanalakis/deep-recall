apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: deep-recall-inference-hpa
spec:
  minReplicas: 2  # Minimum 2 replicas for high availability
  maxReplicas: 20  # Allow more replicas in production
  metrics:
  # CPU-based scaling
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 60  # Lower threshold for production (more proactive scaling)
  # Add GPU utilization based scaling (requires nvidia-device-plugin and custom metrics)
  - type: Pods
    pods:
      metric:
        name: gpu_utilization
      target:
        type: AverageValue
        averageValue: 70  # Scale when GPU utilization exceeds 70%
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 30  # Faster scale-up in production
      policies:
      - type: Percent
        value: 30  # Scale up by 30% at a time
        periodSeconds: 60
      - type: Pods
        value: 2  # But at least 2 pods at a time
        periodSeconds: 60
      selectPolicy: Max  # Select the larger of the two policies
    scaleDown:
      stabilizationWindowSeconds: 600  # Slower scale-down in production
      policies:
      - type: Percent
        value: 10  # Scale down by 10% at a time
        periodSeconds: 300 